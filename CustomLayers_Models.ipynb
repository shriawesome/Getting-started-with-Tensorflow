{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising tensors of 0\n",
    "zero_init=tf.zeros_initializer()\n",
    "tensor_1=zero_init(shape=(2,3))\n",
    "tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[-0.07875424,  0.02862801,  0.02349875, -0.04076311,  0.09593913],\n",
       "       [-0.05641333,  0.05068347, -0.00706676,  0.08815709,  0.02787144],\n",
       "       [-0.07833166, -0.01491617, -0.01577976,  0.00647235,  0.0213961 ],\n",
       "       [ 0.0131471 , -0.05908561, -0.02372928, -0.03818778, -0.02568976]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Normal initializer\n",
    "random_init=tf.random_normal_initializer()\n",
    "tensor_2=random_init((4,5))\n",
    "tensor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a Simple Linear NN forward pass\n",
    "Layer encapsulates state and the transformation from inputs to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(layers.Layer):\n",
    "    \"\"\"\n",
    "    SimpleLinear\n",
    "    ------------------------------------\n",
    "    Parameters :\n",
    "    \n",
    "    input_dims : the total number of input features\n",
    "    units : total number of neurons in the layer\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,input_dims=16,units=8,**kwargs):\n",
    "        super(SimpleLinear,self).__init__(**kwargs)\n",
    "        \n",
    "        w_init=tf.random_normal_initializer()\n",
    "        self.w=tf.Variable(initial_value=w_init(shape=(input_dims,units),\n",
    "                                               dtype='float32'),\n",
    "                          trainable=True)\n",
    "        \n",
    "        b_init=tf.zeros_initializer()\n",
    "        self.b=tf.Variable(initial_value=b_init((units),dtype='float32'),\n",
    "                          trainable=True)\n",
    "        \n",
    "    def call(self,input_tensors):\n",
    "        return tf.matmul(input_tensors,self.w) +self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a random input tensor\n",
    "x=tf.ones((4,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.09334454 -0.21001208 -0.07709382 -0.14670528 -0.02168956]\n",
      " [ 0.09334454 -0.21001208 -0.07709382 -0.14670528 -0.02168956]\n",
      " [ 0.09334454 -0.21001208 -0.07709382 -0.14670528 -0.02168956]\n",
      " [ 0.09334454 -0.21001208 -0.07709382 -0.14670528 -0.02168956]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer1=SimpleLinear(input_dims=3,units=5)\n",
    "\n",
    "y=layer1(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[ 0.06066642, -0.09583402, -0.00462387, -0.07891755, -0.03680738],\n",
       "        [-0.00682286, -0.04210091, -0.00573193, -0.02192286,  0.04349955],\n",
       "        [ 0.03950098, -0.07207714, -0.06673803, -0.04586487, -0.02838173]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the weights\n",
    "layer1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[ 0.06066642, -0.09583402, -0.00462387, -0.07891755, -0.03680738],\n",
       "        [-0.00682286, -0.04210091, -0.00573193, -0.02192286,  0.04349955],\n",
       "        [ 0.03950098, -0.07207714, -0.06673803, -0.04586487, -0.02838173]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the trainable variables that prints both the weights and the \n",
    "# biases associated with the layers.\n",
    "layer1.trainable_variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the nontrainable variables and the losses associated with \n",
    "# each layer\n",
    "layer1.non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "Most of the times if the input features are not known to the user then we can initialise the model via this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(layers.Layer):\n",
    "    \n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.units=units\n",
    "        \n",
    "    # During the forward pass, the layer will automatically call the build()\n",
    "    # method to determine the shape of the inputs and initialize the weights\n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        \n",
    "        self.b=self.add_weight(shape=(self.units),\n",
    "                              initializer='ones',\n",
    "                              trainable=True)\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        return tf.matmul(input_tensor,self.w)+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[-0.03480405,  0.01608697,  0.0406068 , -0.0213593 ,  0.0476276 ],\n",
       "       [-0.01846316, -0.00538139, -0.01598612,  0.047495  , -0.0034514 ],\n",
       "       [-0.01717346,  0.01498104, -0.0374863 ,  0.02571664, -0.03202453],\n",
       "       [-0.03247237, -0.04975696,  0.0196632 ,  0.00270705, -0.00151449]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing input\n",
    "random_uniform=tf.random_uniform_initializer()\n",
    "x=random_uniform((4,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0.99928796, 1.003997  , 1.0009859 ],\n",
       "       [1.007087  , 0.99948615, 0.99897224],\n",
       "       [1.0049851 , 0.9990752 , 0.9992404 ],\n",
       "       [1.0022165 , 0.9998303 , 0.9996735 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a class without the shape of the input variable\n",
    "layers2=SimpleLinear(units=3)\n",
    "y=layers2(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising a Simple Linear NN with more than 1 layer forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear NN with \n",
    "class SimpleLinearBlock(layers.Layer):\n",
    "    \n",
    "    def __init__(self,block1_units=2,block2_units=4,block3_units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.linear_1=SimpleLinear(block1_units)\n",
    "        self.linear_2=SimpleLinear(block2_units)\n",
    "        self.linear_3=SimpleLinear(block3_units)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x=self.linear_1(inputs)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        x=self.linear_2(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        return self.linear_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[1.122722  , 1.0677923 , 0.95541364, 1.0099798 , 0.9330473 ,\n",
       "        1.1277748 , 1.0638983 , 0.99970555],\n",
       "       [1.1227192 , 1.0677736 , 0.9553949 , 1.0100209 , 0.9329959 ,\n",
       "        1.1278129 , 1.0639204 , 0.99966896],\n",
       "       [1.1227196 , 1.0677698 , 0.9553929 , 1.0100329 , 0.9329893 ,\n",
       "        1.1278172 , 1.0639251 , 0.9996704 ],\n",
       "       [1.1227316 , 1.067765  , 0.9554087 , 1.0100839 , 0.93302083,\n",
       "        1.1277869 , 1.0639334 , 0.999764  ]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the object of the class\n",
    "simple_linear_block=SimpleLinearBlock()\n",
    "y=simple_linear_block(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_linear_block_1/simple_linear_5/Variable:0' shape=(5, 2) dtype=float32, numpy=\n",
       " array([[ 0.04144261, -0.06126549],\n",
       "        [-0.04471121,  0.00444007],\n",
       "        [ 0.0218251 , -0.09040137],\n",
       "        [-0.00020006,  0.05664685],\n",
       "        [-0.07753924, -0.0098432 ]], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block_1/simple_linear_5/Variable:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block_1/simple_linear_6/Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[-0.02710937,  0.05976055, -0.13947542,  0.05927534],\n",
       "        [ 0.06308769, -0.01811245, -0.02209657, -0.06563155]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block_1/simple_linear_6/Variable:0' shape=(4,) dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block_1/simple_linear_7/Variable:0' shape=(4, 8) dtype=float32, numpy=\n",
       " array([[-0.00443919,  0.03368673, -0.03452427, -0.03290294, -0.0666955 ,\n",
       "          0.09061263,  0.04286085, -0.11756022],\n",
       "        [ 0.1235817 , -0.01798249, -0.01734117,  0.05659316, -0.03238016,\n",
       "          0.02652675, -0.01440386,  0.07882281],\n",
       "        [ 0.02712941,  0.02828366, -0.00032413, -0.08117688,  0.0177054 ,\n",
       "          0.00070481, -0.02957908, -0.02802752],\n",
       "        [-0.02430169,  0.02806839,  0.00957074,  0.05359612,  0.02113708,\n",
       "          0.00572819,  0.0597057 ,  0.06332964]], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block_1/simple_linear_7/Variable:0' shape=(8,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# includes weights of each \n",
    "simple_linear_block.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing loss associated with the forward pass\n",
    "class RegularizationLoss(layers.Layer):\n",
    "    def __init__(self,rate=1e-3,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.rate=rate\n",
    "        \n",
    "    # layers recursively collects errors from sub layers during forward loss   \n",
    "    def call(self,inputs):\n",
    "        self.add_loss(self.rate*tf.reduce_sum(inputs))\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[-0.03480405,  0.01608697,  0.0406068 , -0.0213593 ,  0.0476276 ],\n",
       "       [-0.01846316, -0.00538139, -0.01598612,  0.047495  , -0.0034514 ],\n",
       "       [-0.01717346,  0.01498104, -0.0374863 ,  0.02571664, -0.03202453],\n",
       "       [-0.03247237, -0.04975696,  0.0196632 ,  0.00270705, -0.00151449]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_loss_layer = RegularizationLoss()\n",
    "\n",
    "y=reg_loss_layer(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=-5.498923e-05>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# losses assciated with each layer is present in the losses\n",
    "reg_loss_layer.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing a Regularized layer with the Outer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegularized(layers.Layer):\n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        \n",
    "        self.units=units\n",
    "        self.reg=RegularizationLoss(1e-2)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        \n",
    "        self.b=self.add_weight(shape=(self.units),\n",
    "                              initializer='ones',\n",
    "                              trainable=True)\n",
    "        \n",
    "    def call(self,input_tensors):\n",
    "        output=tf.matmul(input_tensors,self.w) + self.b\n",
    "        \n",
    "        return self.reg(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1.0021824 , 1.0045875 , 1.0034289 ],\n",
       "       [1.0045444 , 0.9948639 , 0.9975855 ],\n",
       "       [0.99964345, 0.99552417, 0.99516165],\n",
       "       [1.0093046 , 0.99675864, 1.0019703 ]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the same as the input x but there is a loss associated with it \n",
    "# which was previously 0\n",
    "layers3=SimpleLinearRegularized(units=3)\n",
    "y=layers3(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.12005554>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers3.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRegularized(layers.Layer):\n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.dense=layers.Dense(units,kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
    "        \n",
    "        self.reg=RegularizationLoss(1e-2)\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        return self.reg(self.dense(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.03367104, -0.00389524, -0.04225908],\n",
       "       [ 0.01779637, -0.03489458, -0.02151488],\n",
       "       [ 0.04149149, -0.03704301,  0.0076455 ],\n",
       "       [-0.03262861,  0.00650179, -0.04980633]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer5=DenseRegularized(units=3)\n",
    "y=layer5(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0033388846>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-0.0018227763>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st is the loss associated with the dense keras regularizer\n",
    "# and 2nd is the loss associated with the custom loss\n",
    "layer5.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

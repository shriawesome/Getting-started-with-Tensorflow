{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising tensors of 0\n",
    "zero_init=tf.zeros_initializer()\n",
    "tensor_1=zero_init(shape=(2,3))\n",
    "tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as above\n",
    "tf_zeros=tf.zeros((2,3))\n",
    "tf_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[ 0.01854942, -0.02042603, -0.04122335, -0.00379771,  0.02105224],\n",
       "       [-0.01490488,  0.05142501, -0.06348874,  0.01774129,  0.09141453],\n",
       "       [-0.03173401, -0.0306431 , -0.09838222,  0.00302464,  0.10726436],\n",
       "       [-0.03961426, -0.02221404,  0.09078874, -0.00679971,  0.0684964 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Normal initializer\n",
    "random_init=tf.random_normal_initializer()\n",
    "tensor_2=random_init((4,5))\n",
    "tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[-0.46538264, -0.77688086, -0.22244208,  0.16578293, -1.5267727 ],\n",
       "       [ 0.52710867,  0.9672521 , -2.6776025 , -0.5483236 , -0.9444202 ],\n",
       "       [ 0.3775981 , -0.33004266, -1.1166155 ,  1.7185152 ,  0.66213363],\n",
       "       [-0.54758584, -0.23892152, -0.8543801 ,  0.16094948,  0.07029601]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as above\n",
    "tf_rand=tf.random.normal((4,5))\n",
    "tf_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a Simple Linear NN forward pass\n",
    "Layer encapsulates state and the transformation from inputs to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(layers.Layer):\n",
    "    \"\"\"\n",
    "    SimpleLinear\n",
    "    ------------------------------------\n",
    "    Parameters :\n",
    "    \n",
    "    input_dims : the total number of input features\n",
    "    units : total number of neurons in the layer\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,input_dims=16,units=8,**kwargs):\n",
    "        super(SimpleLinear,self).__init__(**kwargs)\n",
    "        \n",
    "        w_init=tf.random_normal_initializer()\n",
    "        self.w=tf.Variable(initial_value=w_init(shape=(input_dims,units),\n",
    "                                               dtype='float32'),\n",
    "                          trainable=True)\n",
    "        \n",
    "        b_init=tf.zeros_initializer()\n",
    "        self.b=tf.Variable(initial_value=b_init((units),dtype='float32'),\n",
    "                          trainable=True)\n",
    "        \n",
    "    def call(self,input_tensors):\n",
    "        return tf.matmul(input_tensors,self.w) +self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a random input tensor\n",
    "x=tf.ones((4,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.11612452  0.0831324   0.00867198 -0.17072874  0.03786272]\n",
      " [ 0.11612452  0.0831324   0.00867198 -0.17072874  0.03786272]\n",
      " [ 0.11612452  0.0831324   0.00867198 -0.17072874  0.03786272]\n",
      " [ 0.11612452  0.0831324   0.00867198 -0.17072874  0.03786272]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer1=SimpleLinear(input_dims=3,units=5)\n",
    "\n",
    "y=layer1(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[ 0.09040371, -0.011307  ,  0.04639702, -0.08460917,  0.02972027],\n",
       "        [ 0.06540506,  0.04370268,  0.02127436, -0.00273685,  0.080735  ],\n",
       "        [-0.03968426,  0.05073672, -0.05899939, -0.08338272, -0.07259255]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the weights\n",
    "layer1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
       " array([[ 0.09040371, -0.011307  ,  0.04639702, -0.08460917,  0.02972027],\n",
       "        [ 0.06540506,  0.04370268,  0.02127436, -0.00273685,  0.080735  ],\n",
       "        [-0.03968426,  0.05073672, -0.05899939, -0.08338272, -0.07259255]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the trainable variables that prints both the weights and the \n",
    "# biases associated with the layers.\n",
    "layer1.trainable_variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the nontrainable variables and the losses associated with \n",
    "# each layer\n",
    "layer1.non_trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "Most of the times if the input features are not known to the user then we can initialise the model via this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(layers.Layer):\n",
    "    \n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.units=units\n",
    "        \n",
    "    # During the forward pass, the layer will automatically call the build()\n",
    "    # method to determine the shape of the inputs and initialize the weights\n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        \n",
    "        self.b=self.add_weight(shape=(self.units),\n",
    "                              initializer='zeros',\n",
    "                              trainable=True)\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        return tf.matmul(input_tensor,self.w)+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[ 0.02411537,  0.02215913,  0.01739193, -0.00579583, -0.01890131],\n",
       "       [ 0.00329667, -0.04309945, -0.02772335, -0.02549037, -0.0420257 ],\n",
       "       [-0.04146206,  0.01574183,  0.02732806,  0.00015129, -0.04524335],\n",
       "       [ 0.03538409,  0.03085747, -0.0420269 , -0.01689041, -0.01858045]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing input\n",
    "random_uniform=tf.random_uniform_initializer()\n",
    "x=random_uniform((4,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 1.8026317e-03, -1.6588890e-03, -1.5355715e-04],\n",
       "       [-3.8269411e-03, -4.4047125e-03, -1.1244778e-03],\n",
       "       [ 7.1851083e-04, -6.3342601e-03, -2.7736407e-03],\n",
       "       [-1.9031190e-03,  1.3972636e-03,  5.2133480e-05]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a class without the shape of the input variable\n",
    "layers2=SimpleLinear(units=3)\n",
    "y=layers2(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_linear_3/Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[ 0.02288637,  0.02370018,  0.03111989],\n",
       "        [ 0.02198828,  0.02547281, -0.00939689],\n",
       "        [ 0.06444674, -0.0463325 , -0.00267053],\n",
       "        [ 0.02962834,  0.0195907 ,  0.02081271],\n",
       "        [ 0.00982235,  0.09922734,  0.02797296]], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_3/Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers2.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising a Simple Linear NN with more than 1 layer forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear NN with \n",
    "class SimpleLinearBlock(layers.Layer):\n",
    "    \n",
    "    def __init__(self,block1_units=2,block2_units=4,block3_units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.linear_1=SimpleLinear(block1_units)\n",
    "        self.linear_2=SimpleLinear(block2_units)\n",
    "        self.linear_3=SimpleLinear(block3_units)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x=self.linear_1(inputs)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        x=self.linear_2(x)\n",
    "        x=tf.nn.relu(x)\n",
    "        \n",
    "        return self.linear_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[-2.35732641e-05,  3.71008355e-05,  2.94589645e-05,\n",
       "        -4.52627755e-05, -1.87013320e-05, -5.42344060e-05,\n",
       "        -1.23551863e-05, -6.07437596e-06],\n",
       "       [-1.77693964e-05,  3.75851523e-05,  2.19213125e-05,\n",
       "        -3.43437750e-05, -2.31909908e-05, -3.93852533e-05,\n",
       "        -9.39373604e-06, -4.93290145e-06],\n",
       "       [-1.43909165e-05,  2.36535325e-05,  1.79542621e-05,\n",
       "        -2.76553292e-05, -1.23662876e-05, -3.29525647e-05,\n",
       "        -7.55094879e-06, -3.74522870e-06],\n",
       "       [-7.52659071e-06,  1.48996842e-05,  9.31541581e-06,\n",
       "        -1.45231461e-05, -8.85840018e-06, -1.68411480e-05,\n",
       "        -3.97037365e-06, -2.05187439e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the object of the class\n",
    "simple_linear_block=SimpleLinearBlock()\n",
    "y=simple_linear_block(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_linear_block/simple_linear_4/Variable:0' shape=(5, 2) dtype=float32, numpy=\n",
       " array([[ 0.05401435,  0.06628237],\n",
       "        [ 0.04976111, -0.01950275],\n",
       "        [ 0.04748801,  0.06493761],\n",
       "        [ 0.11685678, -0.07080941],\n",
       "        [-0.04259014, -0.09224004]], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block/simple_linear_4/Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block/simple_linear_5/Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.04845412, -0.00450532, -0.07156083,  0.0553838 ],\n",
       "        [ 0.01443342,  0.08587965, -0.00231978,  0.09044582]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block/simple_linear_5/Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block/simple_linear_6/Variable:0' shape=(4, 8) dtype=float32, numpy=\n",
       " array([[-0.08398646, -0.03705227, -0.04885611, -0.0585245 , -0.00252851,\n",
       "         -0.09548997, -0.04081266,  0.05805069],\n",
       "        [-0.05738637,  0.03894742, -0.03696844, -0.04044426, -0.06350328,\n",
       "         -0.05393383, -0.02840513,  0.03807821],\n",
       "        [ 0.00324375, -0.10400486,  0.00012613, -0.03262198, -0.00226717,\n",
       "         -0.01122783,  0.00427431, -0.00843667],\n",
       "        [ 0.02812322,  0.05304874,  0.09195933, -0.02912091,  0.00879845,\n",
       "         -0.02169642,  0.01246045, -0.05645963]], dtype=float32)>,\n",
       " <tf.Variable 'simple_linear_block/simple_linear_6/Variable:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# includes weights of each \n",
    "simple_linear_block.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing loss associated with the forward pass\n",
    "class RegularizationLoss(layers.Layer):\n",
    "    def __init__(self,rate=1e-3,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.rate=rate\n",
    "        \n",
    "    # layers recursively collects errors from sub layers during forward loss   \n",
    "    def call(self,inputs):\n",
    "        self.add_loss(self.rate*tf.reduce_sum(inputs))\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[ 0.02411537,  0.02215913,  0.01739193, -0.00579583, -0.01890131],\n",
       "       [ 0.00329667, -0.04309945, -0.02772335, -0.02549037, -0.0420257 ],\n",
       "       [-0.04146206,  0.01574183,  0.02732806,  0.00015129, -0.04524335],\n",
       "       [ 0.03538409,  0.03085747, -0.0420269 , -0.01689041, -0.01858045]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_loss_layer = RegularizationLoss()\n",
    "\n",
    "y=reg_loss_layer(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=-0.00015081333>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# losses assciated with each layer is present in the losses\n",
    "reg_loss_layer.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing a Regularized layer with the Outer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegularized(layers.Layer):\n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        \n",
    "        self.units=units\n",
    "        self.reg=RegularizationLoss(1e-2)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        \n",
    "        self.b=self.add_weight(shape=(self.units),\n",
    "                              initializer='ones',\n",
    "                              trainable=True)\n",
    "        \n",
    "    def call(self,input_tensors):\n",
    "        output=tf.matmul(input_tensors,self.w) + self.b\n",
    "        \n",
    "        return self.reg(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1.002293  , 0.99824136, 0.99779344],\n",
       "       [1.0043979 , 1.0029004 , 1.0003469 ],\n",
       "       [1.0051734 , 0.99598485, 1.0023541 ],\n",
       "       [1.0042342 , 1.00008   , 1.0001353 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the same as the input x but there is a loss associated with it \n",
    "# which was previously 0\n",
    "layers3=SimpleLinearRegularized(units=3)\n",
    "y=layers3(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.120139346>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers3.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRegularized(layers.Layer):\n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.dense=layers.Dense(units,kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
    "        \n",
    "        self.reg=RegularizationLoss(1e-2)\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        return self.reg(self.dense(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.04110644, -0.03522261,  0.01494944],\n",
       "       [-0.01633694,  0.03514275, -0.0403819 ],\n",
       "       [-0.00127417,  0.02554684,  0.05603665],\n",
       "       [-0.01683031, -0.01887583, -0.03015322]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer5=DenseRegularized(units=3)\n",
    "y=layer5(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.004529617>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-0.0006850575>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st is the loss associated with the dense keras regularizer\n",
    "# and 2nd is the loss associated with the custom loss\n",
    "layer5.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(layers.Layer):\n",
    "    \n",
    "    def __init__(self,units=8,**kwargs):\n",
    "        super(SimpleLinear,self).__init__(**kwargs)\n",
    "        self.units=units\n",
    "        \n",
    "    # Helps with the weight initialization\n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(shape=(input_shape[-1],self.units),\n",
    "                              initializer='random_normal',\n",
    "                              trainable=True)\n",
    "        \n",
    "        self.b=self.add_weight(shape=(self.units),\n",
    "                              initializer = 'ones',\n",
    "                              trainable=True)\n",
    "        \n",
    "        \n",
    "    # Helps with the forward pass    \n",
    "    def call(self,input_tensor):\n",
    "        return tf.matmul(input_tensor,self.w)+self.b\n",
    "    \n",
    "    # Useful for Serializing the present Layer\n",
    "    def get_config(self):\n",
    "        config=super().get_config()\n",
    "        config.update({'units':self.units})\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.0000958  0.9993271  0.99694   ]\n",
      " [1.0057142  0.99975365 0.9956415 ]\n",
      " [1.0036721  1.0008075  0.99835485]\n",
      " [1.0041668  1.0016233  0.99682945]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer6=SimpleLinear(units=3)\n",
    "y=layer6(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'simple_linear_9', 'trainable': True, 'dtype': 'float32', 'units': 3}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the get_config, and in our case we only specified the units\n",
    "config=layer6.get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.0021425  1.0014789  1.000758  ]\n",
      " [0.99211645 1.0009811  0.9934833 ]\n",
      " [0.9939109  0.9980058  1.004685  ]\n",
      " [1.0026059  1.0004336  0.99181134]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Build a new layer with the same configuration\n",
    "new_layer6=SimpleLinear.from_config(config)\n",
    "print(new_layer6(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDropout(layers.Layer):\n",
    "    \n",
    "    def __init__(self,rate,**kwargs):\n",
    "        super(CustomDropout,self).__init__(**kwargs)\n",
    "        self.rate=rate\n",
    "        \n",
    "    # needs additional parameter 'training' as the Dropout layer behaves\n",
    "    # differently during training and testing.\n",
    "    def call(self,inputs,training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs,rate=self.rate)\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.02411537  0.02215913  0.01739193 -0.00579583 -0.01890131]\n",
      " [ 0.00329667 -0.04309945 -0.02772335 -0.02549037 -0.0420257 ]\n",
      " [-0.04146206  0.01574183  0.02732806  0.00015129 -0.04524335]\n",
      " [ 0.03538409  0.03085747 -0.0420269  -0.01689041 -0.01858045]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer7=CustomDropout(rate=0.4)\n",
    "\n",
    "print(layer7(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.04019229  0.03693188  0.02898655 -0.00965971 -0.03150219]\n",
      " [ 0.         -0.         -0.         -0.04248394 -0.        ]\n",
      " [-0.          0.02623638  0.04554677  0.         -0.        ]\n",
      " [ 0.05897349  0.05142912 -0.07004483 -0.02815068 -0.03096741]], shape=(4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Nothing happens above as we have training value as None/False\n",
    "# Adding a dropout layer with training=True, by doing this we'll see\n",
    "# that 40% of the data will now have 0 in place.\n",
    "layer7_dropout=CustomDropout(rate=0.4)\n",
    "print(layer7_dropout(x,training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

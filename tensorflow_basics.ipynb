{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the default global graphs.\n",
    "tf.compat.v1.get_default_graph()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()   # by defaulut it is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating constant tensors\n",
    "a=tf.constant(value=5,name='constant_a')    # we have a tensor 'a' with value 5 and name as 'constant_a'\n",
    "b=tf.constant(100,name='constant_b')\n",
    "c=tf.constant(16,name='constant_c')\n",
    "d=tf.constant(8,name='constant_d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link for referring to different operators in tf -<br>\n",
    "https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation(Operator) using Constant (Nodes to the graph)\n",
    "mul=tf.multiply(a,b,name='mul')           # Operator 'multiply' with name 'mul'\n",
    "mul2=tf.multiply(c,d,name='mul2')\n",
    "#div=tf.cast(div,'int32')\n",
    "addn=tf.add_n([mul, mul2],name='addn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"addn:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# info about tensor\n",
    "# Since, we have disbaled eager_execution\n",
    "# the computaton won't be performed  as we are just building the graph and it's not executed it.\n",
    "print(addn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session :-\n",
    "Encapsulates the environment where ```Operation``` objects are executed and ```Tensor``` objects are evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "sess=tf.compat.v1.Session()\n",
    "print(sess.run(addn))   # computes the result and envokes the computation graph\n",
    "print(sess.run(mul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All the api that are used above are low level api's which we use to build our graph in Production.\n",
    "2. `tensorboard` helps to visualise our graph and can be used for debugging.\n",
    "3. To do that we need to instrument our code by writing summary and events in our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an event file and constantly updates that file with events and summaries\n",
    "writer=tf.compat.v1.summary.FileWriter('./constants',sess.graph)   # sess.graph holds the current state of our computation graph\n",
    "\n",
    "writer.close()  # frees up an resources that it is holding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THE TERMINAL COMMAND TO RUN TENSORBOARD :-<br>\n",
    "`tensorboard --logdir='./constants'/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shri/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'variable_m:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring varibales in tf\n",
    "m=tf.compat.v1.Variable([2.5,4.0],tf.float32,name='variable_m')\n",
    "c=tf.compat.v1.Variable([5.0,10.0],tf.float32,name='variable_c')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'placeholder_x:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from above varibale name we are trying to fit in the line with y=mx+c\n",
    "# Placeholder or empty container for tensor values which will be fed in during the execution\n",
    "x=tf.compat.v1.placeholder(tf.float32,shape=[2],name='placeholder_x')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equation of the line\n",
    "y=m*x+c\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before using any variables we need to explicitly initialise it\n",
    "# Operator needs to be called to initialise all the variables in th graph\n",
    "init=tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result:mx + c [ 55. 210.]\n",
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "tf.float32 has type DType, but expected one of: int, long, bool\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "tf.float32 has type DType, but expected one of: int, long, bool\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_output=sess.run(y,feed_dict={x:[20.0,50.0]})\n",
    "    print(\"Final result:mx + c\",y_output)\n",
    "    writer=tf.compat.v1.summary.FileWriter('./variables_and_placeholders',sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55., 210.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising only a particular variable in place of all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result m*n is :[ 50. 800.]\n"
     ]
    }
   ],
   "source": [
    "s=m*x\n",
    "init=tf.compat.v1.variables_initializer([m])   # initialise only variable m\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Result m*n is :{}\".format(sess.run(s,feed_dict={x:[20,200]})))\n",
    "  # print(\"Result y :{}\".format(sess.run(y,feed_dict={x:[20,200]})))   # this will produce an error as c is not init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating a Variable within the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubler=tf.compat.v2.Variable(1)      # Doubles the value in each iteration.\n",
    "incrementor=tf.compat.v2.Variable(1)  # Increments the value by one.\n",
    "\n",
    "init=tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Doubler :2\n",
      "Value of Doubler :4\n",
      "Value of Doubler :8\n",
      "Value of Doubler :16\n",
      "Value of Doubler :32\n",
      "Value of Doubler :64\n",
      "Value of Doubler :128\n",
      "Value of Doubler :256\n",
      "Value of Doubler :512\n",
      "Value of Doubler :1024\n",
      "Value of incrementor :2\n",
      "Value of incrementor :3\n",
      "Value of incrementor :4\n",
      "Value of incrementor :5\n",
      "Value of incrementor :6\n",
      "Value of incrementor :7\n",
      "Value of incrementor :8\n",
      "Value of incrementor :9\n",
      "Value of incrementor :10\n",
      "Value of incrementor :11\n"
     ]
    }
   ],
   "source": [
    "result=doubler.assign(tf.add(doubler,doubler))\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(\"Value of Doubler :{}\".format(sess.run(result)))\n",
    "        \n",
    "    for i in range(10):\n",
    "        print(\"Value of incrementor :{}\".format(sess.run(incrementor.assign_add(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus from the above code we can understand that the variables are trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding fetch_dict with linear equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the default graph\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring 1D tensor vectors\n",
    "a=tf.constant([1,10],name='constant_a')\n",
    "b=tf.constant([10,100],name='constant_b')\n",
    "c=tf.constant([100,1000],name='constant_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring place holders i.e. weights for respective constants\n",
    "x_1=tf.compat.v1.placeholder(tf.int32,name='x_1')\n",
    "x_2=tf.compat.v1.placeholder(tf.int32,name='x_2')\n",
    "x_3=tf.compat.v1.placeholder(tf.int32,name='x_3')\n",
    "\n",
    "#multiplying each placeholder with corresponding constants\n",
    "ax_1=tf.multiply(a,x_1,name='ax_1')\n",
    "bx_2=tf.multiply(b,x_2,name='bx_2')\n",
    "cx_3=tf.multiply(c,x_3,name='cx_3')\n",
    "\n",
    "# Calculating y_sub\n",
    "with tf.name_scope('subtract'):\n",
    "    y_sub=tf.subtract(bx_2,ax_1,name='y_sub')\n",
    "\n",
    "# Calculating y_add\n",
    "with tf.name_scope('Add'):\n",
    "    y_add=ax_1+bx_2+cx_3\n",
    "with tf.name_scope('Final'):\n",
    "    y_final=y_add * y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of ax_1: [  4 440]\n",
      "Value of y_sub: [  66 7260]\n",
      "Value of y_final: [    18084 218816400]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    print(\"Value of ax_1: {}\".format(sess.run(fetches=ax_1,feed_dict={x_1:[4,44]})))\n",
    "    \n",
    "    print(\"Value of y_sub: {}\".format(sess.run(fetches=y_sub,feed_dict={x_1:[4,44],x_2:[7,77]})))\n",
    "    \n",
    "    print(\"Value of y_final: {}\".format(sess.run(y_final,feed_dict={x_1:[4,44],x_2:[7,77],x_3:[2,22]})))\n",
    "    \n",
    "    writer=tf.compat.v1.summary.FileWriter('./fetches_feeddict',sess.graph)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When visualising the graph we can see a graph without any order. Hence, we can group certain operations together<br>\n",
    "by using something called as the name_scope()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Eager Execution \n",
    "Till now we have executed the code in static mode where Building a graph and Executing it are in two different phases. Well now by enhancement in modules we can combine these two discrete steps into one by the added functionality called as `Eager Execution`. By default in tf v2.1.0 it is automatically enabled but to start it again we can use the following command.To do this restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by creating a Multidimensional numpy array\n",
    "a=np.array([[10,11],[12,13]])\n",
    "b=np.ones([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[11, 12],\n",
       "       [13, 14]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum=tf.add(a,b)\n",
    "sum    # Hence we can see that the tensors are already created and Executed in a single go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[100, 121],\n",
       "       [144, 169]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqr=tf.square(a)\n",
    "sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE :-<BR>\n",
    "    For Production task in the industry people prefer to use the static mode as it can use the ability of the  CPUs and GPUs to perform task parallely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
